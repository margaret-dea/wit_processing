{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b70e05-52d2-411f-8c3c-6d9d0fd1e17f",
   "metadata": {},
   "source": [
    "# Zip the files into 10 folders and send to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0574c-cb0c-4682-9da6-68f2414966ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b69116-9406-49bf-a9d4-56e7fe96a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_aws_access_key_id=\"\"\n",
    "temp_aws_secret_access_key=\"\"\n",
    "temp_aws_session_token=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa03f4-dc91-421c-b5f1-d3f0b643dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client  = boto3.client('s3', aws_access_key_id=temp_aws_access_key_id,\n",
    "                      aws_secret_access_key=temp_aws_secret_access_key, \n",
    "                 aws_session_token=temp_aws_session_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21b751-ef8c-4065-bf99-22156d380162",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bucket = 'dea-public-data-dev'\n",
    "source_prefix = 'projects/WIT/MDBA_ANAE_WIT_MH_18_04_2025/merged/'\n",
    "\n",
    "# list all files in the source folder\n",
    "response = s3_client.list_objects_v2(Bucket=source_bucket, Prefix=source_prefix)\n",
    "\n",
    "# gather all file keys\n",
    "file_keys = [obj['Key'] for obj in response.get('Contents', [])]\n",
    "\n",
    "# display the first 10 file keys to verify\n",
    "file_keys[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834c4f1-17f9-41de-8f2c-219de6aa9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_bucket = 'dea-public-data-dev'\n",
    "destination_prefix = 'projects/WIT/ANAEv3_WIT_result_22042025/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd2f80-8d51-4494-b3a9-04f8e3eff943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a temporary directory to store files for zipping\n",
    "temp_dir = '/tmp/s3_zip_temp'\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# list files\n",
    "print(\"Listing files in S3...\")\n",
    "paginator = s3_client.get_paginator('list_objects_v2')\n",
    "page_iterator = paginator.paginate(Bucket=source_bucket, Prefix=source_prefix)\n",
    "\n",
    "file_keys = []\n",
    "for page in tqdm(page_iterator, desc=\"Fetching file list\"):\n",
    "    file_keys.extend(obj['Key'] for obj in page.get('Contents', []))\n",
    "\n",
    "print(f\"Total files: {len(file_keys)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28462441-6d01-4188-b244-f1440b526535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def download_files(file_keys, download_dir, max_workers=16):\n",
    "    def download(key):\n",
    "        filename = os.path.basename(key)\n",
    "        dest_path = os.path.join(download_dir, filename)\n",
    "        s3_client.download_file(source_bucket, key, dest_path)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        list(tqdm(executor.map(download, file_keys), total=len(file_keys), desc=\"Downloading\"))\n",
    "\n",
    "def zip_files(files, zip_name):\n",
    "    \"\"\"Create zip file with progress bar\"\"\"\n",
    "    zip_path = os.path.join(temp_dir, zip_name)\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for file in tqdm(files, desc=f\"Zipping {zip_name}\", leave=False):\n",
    "            zipf.write(file, os.path.basename(file))\n",
    "\n",
    "def upload_zip(zip_file, destination_key):\n",
    "    \"\"\"Upload zip file to S3\"\"\"\n",
    "    tqdm.write(f\"Uploading {os.path.basename(zip_file)} to S3...\")\n",
    "    s3_client.upload_file(zip_file, destination_bucket, destination_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44568907-9524-4951-bd2a-43b9f4f40b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_per_zip = 27066\n",
    "last_zip_files = 27059\n",
    "total_files = len(file_keys)\n",
    "\n",
    "for i in range(0, total_files, files_per_zip):\n",
    "    if i + files_per_zip > total_files:\n",
    "        group_files = file_keys[i:i + last_zip_files]\n",
    "    else:\n",
    "        group_files = file_keys[i:i + files_per_zip]\n",
    "\n",
    "    part_num = i // files_per_zip\n",
    "    zip_name = f\"ANAE_WIT_result_2025_04-part-{part_num}.zip\"\n",
    "    tqdm.write(f\"\\nüì¶ Processing {zip_name} ({len(group_files)} files)\")\n",
    "\n",
    "    # download \n",
    "    download_files(group_files, temp_dir)\n",
    "\n",
    "    # zip\n",
    "    local_file_paths = [os.path.join(temp_dir, os.path.basename(f)) for f in group_files]\n",
    "    zip_files(local_file_paths, zip_name)\n",
    "\n",
    "    # upload to S3\n",
    "    destination_key = f\"{destination_prefix}{zip_name}\"\n",
    "    upload_zip(os.path.join(temp_dir, zip_name), destination_key)\n",
    "\n",
    "    # clean up\n",
    "    shutil.rmtree(temp_dir)\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\n‚úÖ All zip files created and uploaded to S3 successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab762609-c368-4c09-8e12-1ba51225377d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f90a0735-4cbb-4609-90f5-4cd4336eda96",
   "metadata": {},
   "source": [
    "### verification before sending "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f24448-1f10-47a2-b6ac-ddcb6439d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import zipfile\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Config ===\n",
    "destination_bucket = \"dea-public-data-dev\"\n",
    "destination_prefix = \"projects/WIT/ANAEv3_WIT_result_22042025/\"\n",
    "expected_counts = [27066] * 9 + [27059]\n",
    "total_expected_files = sum(expected_counts)\n",
    "\n",
    "zip_names = [f\"ANAE_WIT_result_2025_04-part-{i}.zip\" for i in range(10)]\n",
    "\n",
    "# === Setup ===\n",
    "s3_client = boto3.client('s3')\n",
    "verify_temp_dir = tempfile.mkdtemp()\n",
    "all_filenames = []\n",
    "\n",
    "print(\"üîç Starting verification...\\n\")\n",
    "\n",
    "# verify each zip file \n",
    "for i, zip_name in enumerate(tqdm(zip_names, desc=\"Verifying zip files\")):\n",
    "    zip_path = os.path.join(verify_temp_dir, zip_name)\n",
    "    destination_key = f\"{destination_prefix}{zip_name}\"\n",
    "\n",
    "    # download zip\n",
    "    try:\n",
    "        s3_client.download_file(destination_bucket, destination_key, zip_path)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to download {zip_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "            # test for corruption\n",
    "            bad_file = zipf.testzip()\n",
    "            if bad_file:\n",
    "                print(f\"‚ùå Corrupt file in {zip_name}: {bad_file}\")\n",
    "                continue\n",
    "\n",
    "            file_list = zipf.namelist()\n",
    "            all_filenames.extend(file_list)\n",
    "\n",
    "            # Check count\n",
    "            actual_count = len(file_list)\n",
    "            expected_count = expected_counts[i]\n",
    "            if actual_count != expected_count:\n",
    "                print(f\"‚ö†Ô∏è {zip_name} has {actual_count} files, expected {expected_count}\")\n",
    "            else:\n",
    "                print(f\"‚úÖ {zip_name}: {actual_count} files\")\n",
    "\n",
    "            # check for empty files\n",
    "            empty_files = [f.filename for f in zipf.infolist() if f.file_size == 0]\n",
    "            if empty_files:\n",
    "                print(f\"‚ö†Ô∏è Empty files in {zip_name}: {empty_files}\")\n",
    "\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"‚ùå {zip_name} is not a valid zip file.\")\n",
    "\n",
    "# global checks\n",
    "\n",
    "# check total number of files\n",
    "total_files = len(all_filenames)\n",
    "print(f\"\\nüì¶ Total files across all zips: {total_files}\")\n",
    "if total_files != total_expected_files:\n",
    "    print(f\"‚ùå Expected {total_expected_files} files, but found {total_files}\")\n",
    "else:\n",
    "    print(\"‚úÖ Total file count matches expected.\")\n",
    "\n",
    "# check uniqueness of filenames\n",
    "file_counts = Counter(all_filenames)\n",
    "duplicates = [f for f, count in file_counts.items() if count > 1]\n",
    "\n",
    "if duplicates:\n",
    "    print(f\"\\n‚ùå Found duplicate filenames across zips ({len(duplicates)}):\")\n",
    "    for dup in duplicates:\n",
    "        print(f\" - {dup}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All filenames are unique across all zip files.\")\n",
    "\n",
    "# clean up\n",
    "shutil.rmtree(verify_temp_dir)\n",
    "print(\"\\nüßπ Temp files cleaned up.\")\n",
    "print(\"\\nüéâ Verification complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59fed2a-d8a6-4b39-b663-d85ae7cf0edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295fa08-7de8-4bf5-bd02-40692284f644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ddf26-f510-413a-baf5-ab66b179176c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71794225-2895-4e29-bb05-9b5a62eb1de0",
   "metadata": {},
   "source": [
    "### Use for dry run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebef6bc-e99b-4fa5-b691-60c2b5c8d275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRY RUN: Use only the first 100 files\n",
    "dry_run_file_count = 100\n",
    "group_files = file_keys[:dry_run_file_count]\n",
    "\n",
    "# Set a test zip name\n",
    "zip_name = \"ANAE_WIT_result_2025_04-part-TEST.zip\"\n",
    "tqdm.write(f\"\\nüöß DRY RUN: Processing {zip_name} with {len(group_files)} files\")\n",
    "\n",
    "# Download files\n",
    "download_files(group_files, temp_dir)\n",
    "\n",
    "# Zip files\n",
    "local_file_paths = [os.path.join(temp_dir, os.path.basename(f)) for f in group_files]\n",
    "zip_files(local_file_paths, zip_name)\n",
    "\n",
    "# Upload zip to S3\n",
    "destination_key = f\"{destination_prefix}{zip_name}\"\n",
    "upload_zip(os.path.join(temp_dir, zip_name), destination_key)\n",
    "\n",
    "# Clean up\n",
    "shutil.rmtree(temp_dir)\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\n‚úÖ DRY RUN complete ‚Äî test zip uploaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f9682-d25a-4e9f-8bf8-f2cf1c52728c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
